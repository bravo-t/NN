mode = train
number_of_samples = 10
data_set = test_data/mnist.txt
correct_labels = test_data/cnn_labels.txt
M = 2
N = 1
labels = 10
minibatch_size = 10
alpha = 1e-3
learning_rate = 1e-3
epochs = 2000
hidden_layer_sizes = 100,10
filter_number = 16,16
filter_stride = 1,1
filter_size = 5,5
enable_maxpooling = 1,1
pooling_stride = 2,3
pooling_size = 2,3
padding_size = 0,2
use_rmsprop = 1
rmsprop_decay_rate = 0.9
rmsprop_eps = 1e-5
normalize_data_per_channel = 1
enable_learning_rate_step_decay = 1
enable_learning_rate_exponential_decay = 0
enable_learning_rate_invert_t_decay = 0
learning_rate_decay_unit = 250
learning_rate_decay_a0 = 1.0
learning_rate_decay_k = 0.9
verbose = 0
shuffle_training_samples = 50
vertically_flip_training_samples = 1
horizontally_flip_training_samples = 1
params_dir = .
